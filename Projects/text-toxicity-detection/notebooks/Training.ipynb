{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import spacy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Data/preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=5000, ngram_range=(1, 5))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=5000, ngram_range=(1, 5))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=5000, ngram_range=(1, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 5), max_features=5000)\n",
    "vectorizer.fit(data['comment_text'])\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 5000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 5),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_border = int(len(data)*0.6)\n",
    "validation_set = data[val_border:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'comment_text', 'toxic', 'severe_toxic', 'obscene',\n",
       "       'threat', 'insult', 'identity_hate', 'num_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.transform(data['comment_text'])\n",
    "target_columns = ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     57681\n",
      "           1       0.90      0.58      0.71      6079\n",
      "\n",
      "    accuracy                           0.95     63760\n",
      "   macro avg       0.93      0.79      0.84     63760\n",
      "weighted avg       0.95      0.95      0.95     63760\n",
      "\n",
      "AUC: 0.786612570646289\n",
      "Label = severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63125\n",
      "           1       0.58      0.25      0.35       635\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.79      0.63      0.67     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.625073360879395\n",
      "Label = obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     60405\n",
      "           1       0.90      0.63      0.74      3355\n",
      "\n",
      "    accuracy                           0.98     63760\n",
      "   macro avg       0.94      0.82      0.87     63760\n",
      "weighted avg       0.98      0.98      0.98     63760\n",
      "\n",
      "AUC: 0.8150940293604361\n",
      "Label = threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63587\n",
      "           1       0.62      0.09      0.16       173\n",
      "\n",
      "    accuracy                           1.00     63760\n",
      "   macro avg       0.81      0.55      0.58     63760\n",
      "weighted avg       1.00      1.00      1.00     63760\n",
      "\n",
      "AUC: 0.5461641421416072\n",
      "Label = insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     60640\n",
      "           1       0.82      0.52      0.63      3120\n",
      "\n",
      "    accuracy                           0.97     63760\n",
      "   macro avg       0.90      0.76      0.81     63760\n",
      "weighted avg       0.97      0.97      0.97     63760\n",
      "\n",
      "AUC: 0.7566223107367567\n",
      "Label = identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63167\n",
      "           1       0.65      0.17      0.26       593\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.82      0.58      0.63     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.5822190840730523\n",
      "Average AUC: 0.6852975829729226\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(solver='liblinear')\n",
    "average_roc = 0\n",
    "    \n",
    "for label in target_columns:\n",
    "    lr_classifier.fit(x_train[:val_border], data[label][:val_border])\n",
    "    predictions = lr_classifier.predict(x_train[val_border:])\n",
    "    print(f'Label = {label}')\n",
    "    print(classification_report(validation_set[label], predictions))\n",
    "    print(f'AUC: {roc_auc_score(validation_set[label], predictions)}')\n",
    "    average_roc += roc_auc_score(validation_set[label], predictions)\n",
    "                                 \n",
    "print(f'Average AUC: {average_roc/len(target_columns)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     57681\n",
      "           1       0.91      0.59      0.71      6079\n",
      "\n",
      "    accuracy                           0.95     63760\n",
      "   macro avg       0.93      0.79      0.84     63760\n",
      "weighted avg       0.95      0.95      0.95     63760\n",
      "\n",
      "AUC: 0.791132105924126\n",
      "Label = severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63125\n",
      "           1       0.60      0.10      0.17       635\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.80      0.55      0.58     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.5492736259452716\n",
      "Label = obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     60405\n",
      "           1       0.90      0.68      0.77      3355\n",
      "\n",
      "    accuracy                           0.98     63760\n",
      "   macro avg       0.94      0.84      0.88     63760\n",
      "weighted avg       0.98      0.98      0.98     63760\n",
      "\n",
      "AUC: 0.8359750398175455\n",
      "Label = threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63587\n",
      "           1       0.82      0.05      0.10       173\n",
      "\n",
      "    accuracy                           1.00     63760\n",
      "   macro avg       0.91      0.53      0.55     63760\n",
      "weighted avg       1.00      1.00      1.00     63760\n",
      "\n",
      "AUC: 0.5259958342086682\n",
      "Label = insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     60640\n",
      "           1       0.80      0.57      0.66      3120\n",
      "\n",
      "    accuracy                           0.97     63760\n",
      "   macro avg       0.89      0.78      0.82     63760\n",
      "weighted avg       0.97      0.97      0.97     63760\n",
      "\n",
      "AUC: 0.7798939516947432\n",
      "Label = identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63167\n",
      "           1       0.81      0.15      0.25       593\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.90      0.57      0.62     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.5740406776853808\n",
      "Average AUC: 0.676051872545956\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM-classifier based on TF-IDF\n",
    "\n",
    "sv_classifier = SVC()\n",
    "average_roc = 0\n",
    "    \n",
    "for label in target_columns:\n",
    "    sv_classifier.fit(x_train[:val_border], data[label][:val_border])\n",
    "    predictions = sv_classifier.predict(x_train[val_border:])\n",
    "    print(f'Label = {label}')\n",
    "    print(classification_report(validation_set[label], predictions))\n",
    "    print(f'AUC: {roc_auc_score(validation_set[label], predictions)}')\n",
    "    average_roc += roc_auc_score(validation_set[label], predictions)\n",
    "                                 \n",
    "print(f'Average AUC: {average_roc/len(target_columns)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label = toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     57681\n",
      "           1       0.77      0.65      0.71      6079\n",
      "\n",
      "    accuracy                           0.95     63760\n",
      "   macro avg       0.87      0.82      0.84     63760\n",
      "weighted avg       0.95      0.95      0.95     63760\n",
      "\n",
      "AUC: 0.8166472028418869\n",
      "Label = severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63125\n",
      "           1       0.43      0.30      0.35       635\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.71      0.65      0.67     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.6468307788259141\n",
      "Label = obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     60405\n",
      "           1       0.81      0.71      0.75      3355\n",
      "\n",
      "    accuracy                           0.98     63760\n",
      "   macro avg       0.90      0.85      0.87     63760\n",
      "weighted avg       0.97      0.98      0.97     63760\n",
      "\n",
      "AUC: 0.8483949313322356\n",
      "Label = threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63587\n",
      "           1       0.44      0.29      0.35       173\n",
      "\n",
      "    accuracy                           1.00     63760\n",
      "   macro avg       0.72      0.65      0.68     63760\n",
      "weighted avg       1.00      1.00      1.00     63760\n",
      "\n",
      "AUC: 0.6468955964114889\n",
      "Label = insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     60640\n",
      "           1       0.70      0.57      0.63      3120\n",
      "\n",
      "    accuracy                           0.97     63760\n",
      "   macro avg       0.84      0.78      0.81     63760\n",
      "weighted avg       0.96      0.97      0.97     63760\n",
      "\n",
      "AUC: 0.7805265205331168\n",
      "Label = identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63167\n",
      "           1       0.54      0.31      0.39       593\n",
      "\n",
      "    accuracy                           0.99     63760\n",
      "   macro avg       0.77      0.65      0.69     63760\n",
      "weighted avg       0.99      0.99      0.99     63760\n",
      "\n",
      "AUC: 0.653892685923614\n",
      "Average AUC: 0.7321979526447094\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-Layer Perceptron Classifier based on TF-IDF\n",
    "\n",
    "mlp_classifier = MLPClassifier(max_iter=500)\n",
    "average_roc = 0\n",
    "    \n",
    "for label in target_columns:\n",
    "    mlp_classifier.fit(x_train[:val_border], data[label][:val_border])\n",
    "    predictions = mlp_classifier.predict(x_train[val_border:])\n",
    "    print(f'Label = {label}')\n",
    "    print(classification_report(validation_set[label], predictions))\n",
    "    print(f'AUC: {roc_auc_score(validation_set[label], predictions)}')\n",
    "    average_roc += roc_auc_score(validation_set[label], predictions)\n",
    "                                 \n",
    "print(f'Average AUC: {average_roc/len(target_columns)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('text-toxicity-detection-BTqULhGY-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ccadf1cc4a0363684c4865dfec263580c3b51092ac60651030ebc952f3d18e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
